{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeabb31f-8873-44b6-ab98-a29d0137452f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample feature names after TF-IDF vectorization:\n",
      "['accessible' 'accessible food' 'accessible location' 'accommodate'\n",
      " 'accommodate chicken' 'accommodate clean' 'accommodate delicious'\n",
      " 'accommodate family' 'accommodate food' 'accommodate gluten']\n",
      "Topic 1:\n",
      "['best', 'staff', 'minutes', 'table', 'love', 'pho', 'time', 'good', 'service', 'food']\n",
      "Topic 2:\n",
      "['shrimp', 'fried', 'sauce', 'service', 'time', 'rice', 'sushi', 'chicken', 'good', 'food']\n",
      "Topic 3:\n",
      "['new', 'food delicious', 'best', 'recommend', 'amazing', 'service', 'friendly', 'delicious', 'pizza', 'food']\n",
      "Topic 4:\n",
      "['location', 'pork', 'chicken', 'pho', 'beef', 'food', 'sushi', 'soup', 'ramen', 'good']\n",
      "Topic 5:\n",
      "['price', 'chicken', 'portion', 'amazing', 'recommend', 'love', 'burger', 'food', 'vegan', 'delicious']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pandas as pd\n",
    "\n",
    "filtered_reviews = pd.read_csv('clean_filtered_reviews.csv')\n",
    "\n",
    "filtered_reviews = filtered_reviews.dropna(subset=['all_text'])\n",
    "\n",
    "# Use TF-IDF Vectorizer with bigrams for richer context\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.9, min_df=2, stop_words='english', ngram_range=(1, 2))\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(filtered_reviews['all_text'])\n",
    "\n",
    "# Display feature names to verify the refined vocabulary\n",
    "print(\"Sample feature names after TF-IDF vectorization:\")\n",
    "print(tfidf_vectorizer.get_feature_names_out()[:10])\n",
    "\n",
    "# Fit LDA model\n",
    "num_topics = 5\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda.fit(tfidf_matrix)\n",
    "\n",
    "# Display topics\n",
    "def display_topics(model, feature_names, num_top_words):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {idx + 1}:\")\n",
    "        print([feature_names[i] for i in topic.argsort()[-num_top_words:]])\n",
    "\n",
    "# Display top 10 words for each topic\n",
    "display_topics(lda, tfidf_vectorizer.get_feature_names_out(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b3e0419-3a2c-4c5b-8a9d-e5f5042965b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of sentiment scores added to DataFrame:\n",
      "                                            all_text  sentiment_score\n",
      "0  love kind time good last time staff friendly long           0.9287\n",
      "1  disappointed chicken chicken chicken fried ric...          -0.0516\n",
      "2                    good flavour salad service come           0.4404\n",
      "3                        minutes interior asked back           0.0000\n",
      "4                tasty good area friendly food quick           0.7269\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "# Download VADER lexicon if not already done\n",
    "#nltk.download('vader_lexicon')\n",
    "\n",
    "# Instantiate Sentiment Intensity Analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to calculate sentiment scores using VADER\n",
    "def calculate_sentiment(text):\n",
    "    score = sia.polarity_scores(text)\n",
    "    return score['compound']  # Return the compound score which reflects the overall sentiment\n",
    "\n",
    "# Apply the function to calculate sentiment score for each review\n",
    "filtered_reviews['sentiment_score'] = filtered_reviews['all_text'].apply(calculate_sentiment)\n",
    "\n",
    "# Verify that the sentiment scores have been added\n",
    "print(\"Sample of sentiment scores added to DataFrame:\")\n",
    "print(filtered_reviews[['all_text', 'sentiment_score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a09c2660-913f-4ce1-b2df-8ae1350464f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sentiment for Topic 1: 0.58713499413069\n",
      "Average Sentiment for Topic 2: 0.5716405899781013\n",
      "Average Sentiment for Topic 3: 0.598892210015694\n",
      "Average Sentiment for Topic 4: 0.5818306917572224\n",
      "Average Sentiment for Topic 5: 0.5976915769566482\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have sentiment scores already computed for each review\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    # Identify relevant reviews based on words in the topic\n",
    "    relevant_words = [tfidf_vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]]\n",
    "    relevant_reviews = filtered_reviews[filtered_reviews['all_text'].apply(lambda x: any(word in x for word in relevant_words))]\n",
    "    \n",
    "    # Calculate the average sentiment score for the relevant reviews\n",
    "    avg_sentiment = relevant_reviews['sentiment_score'].mean()\n",
    "    print(f\"Average Sentiment for Topic {idx + 1}: {avg_sentiment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
